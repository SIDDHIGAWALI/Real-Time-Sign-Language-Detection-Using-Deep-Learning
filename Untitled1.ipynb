{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19d75d1-db1d-4c31-90a0-dd69aa7b2355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet ASL Detection Started. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# ASL Classes\n",
    "ASL_CLASSES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',\n",
    "               'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "               'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "\n",
    "def create_resnet_model(num_classes):\n",
    "    \"\"\"Create ResNet18 model\"\"\"\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_resnet_model(model_path, num_classes=29):\n",
    "    \"\"\"Load trained ResNet model\"\"\"\n",
    "    model = create_resnet_model(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_frame(frame, image_size=224):\n",
    "    \"\"\"Preprocess frame for ResNet\"\"\"\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "    \n",
    "    # Apply transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    tensor = transform(pil_image).unsqueeze(0)\n",
    "    return tensor\n",
    "\n",
    "def run_resnet_detection():\n",
    "    \"\"\"Run real-time ASL detection with ResNet\"\"\"\n",
    "    # Load model\n",
    "    model_path = \"models/asl_resnet_model.pth\"\n",
    "    model = load_resnet_model(model_path)\n",
    "    \n",
    "    # Initialize camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    print(\"ResNet ASL Detection Started. Press 'q' to quit.\")\n",
    "    \n",
    "    # For prediction smoothing\n",
    "    prediction_history = []\n",
    "    history_size = 5\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Create ROI for hand detection\n",
    "        h, w = frame.shape[:2]\n",
    "        roi_size = 300\n",
    "        x1 = (w - roi_size) // 2\n",
    "        y1 = (h - roi_size) // 2\n",
    "        x2 = x1 + roi_size\n",
    "        y2 = y1 + roi_size\n",
    "        \n",
    "        # Extract ROI\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # Preprocess and predict\n",
    "        input_tensor = preprocess_frame(roi)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probabilities, 1)\n",
    "            \n",
    "            predicted_class = ASL_CLASSES[predicted.item()]\n",
    "            confidence_score = confidence.item()\n",
    "        \n",
    "        # Smooth predictions\n",
    "        prediction_history.append((predicted_class, confidence_score))\n",
    "        if len(prediction_history) > history_size:\n",
    "            prediction_history.pop(0)\n",
    "        \n",
    "        # Get most frequent prediction if confidence > 0.7\n",
    "        if confidence_score > 0.7:\n",
    "            most_common = max(set([p[0] for p in prediction_history]), \n",
    "                            key=[p[0] for p in prediction_history].count)\n",
    "            display_text = f\"Prediction: {most_common} ({confidence_score:.2f})\"\n",
    "        else:\n",
    "            display_text = \"Low Confidence\"\n",
    "        \n",
    "        # Draw ROI rectangle\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display prediction\n",
    "        cv2.putText(frame, display_text, (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"ResNet Model\", (10, 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, \"Place hand in green box\", (10, h-20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        cv2.imshow('ASL Detection - ResNet', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_resnet_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e005bb3b-79dd-479b-9292-020d27c7c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Enhanced ASL Detection with Finger Spelling Started!\n",
      "Controls:\n",
      "  Hold gestures to spell words\n",
      "  C - Clear all\n",
      "  U - Undo last word\n",
      "  S - Save session\n",
      "  Q - Quit\n",
      "Final sentence: wbcciiiiiiii\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from collections import deque, Counter\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ASL Classes\n",
    "ASL_CLASSES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',\n",
    "               'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "               'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "\n",
    "class FingerSpellingEngine:\n",
    "    def __init__(self):\n",
    "        self.current_word = \"\"\n",
    "        self.sentence = \"\"\n",
    "        self.word_history = []\n",
    "        self.last_prediction = \"\"\n",
    "        self.last_prediction_time = 0\n",
    "        self.prediction_hold_time = 1.5  # seconds to hold a prediction\n",
    "        self.delete_hold_time = 2.0  # seconds to hold delete\n",
    "        self.space_hold_time = 1.0   # seconds to hold space\n",
    "        \n",
    "        # Load common words dictionary for auto-correct suggestions\n",
    "        self.common_words = self.load_common_words()\n",
    "        \n",
    "        # Prediction smoothing\n",
    "        self.prediction_buffer = deque(maxlen=10)\n",
    "        self.confidence_threshold = 0.75\n",
    "        \n",
    "    def load_common_words(self):\n",
    "        \"\"\"Load common English words for auto-correction\"\"\"\n",
    "        # You can replace this with a file containing common words\n",
    "        common_words = [\n",
    "            'hello', 'world', 'how', 'are', 'you', 'what', 'when', 'where', \n",
    "            'why', 'who', 'good', 'bad', 'yes', 'no', 'please', 'thank', \n",
    "            'sorry', 'help', 'love', 'like', 'want', 'need', 'time', 'day',\n",
    "            'night', 'morning', 'afternoon', 'evening', 'food', 'water',\n",
    "            'home', 'work', 'school', 'friend', 'family', 'happy', 'sad',\n",
    "            'the', 'and', 'for', 'with', 'this', 'that', 'have', 'will',\n",
    "            'can', 'could', 'should', 'would', 'make', 'take', 'give',\n",
    "            'get', 'go', 'come', 'see', 'know', 'think', 'feel', 'look'\n",
    "        ]\n",
    "        return set(common_words)\n",
    "    \n",
    "    def smooth_prediction(self, predicted_class, confidence):\n",
    "        \"\"\"Smooth predictions using a buffer\"\"\"\n",
    "        self.prediction_buffer.append((predicted_class, confidence))\n",
    "        \n",
    "        # Only consider high confidence predictions\n",
    "        high_conf_predictions = [pred for pred, conf in self.prediction_buffer if conf > self.confidence_threshold]\n",
    "        \n",
    "        if len(high_conf_predictions) < 3:  # Need at least 3 consistent predictions\n",
    "            return None, 0\n",
    "        \n",
    "        # Get most common prediction\n",
    "        counter = Counter(high_conf_predictions)\n",
    "        most_common_pred, count = counter.most_common(1)[0]\n",
    "        \n",
    "        # Calculate average confidence for the most common prediction\n",
    "        avg_confidence = np.mean([conf for pred, conf in self.prediction_buffer if pred == most_common_pred])\n",
    "        \n",
    "        return most_common_pred, avg_confidence\n",
    "    \n",
    "    def process_prediction(self, predicted_class, confidence):\n",
    "        \"\"\"Process the prediction and update word/sentence\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Smooth the prediction\n",
    "        smoothed_pred, smoothed_conf = self.smooth_prediction(predicted_class, confidence)\n",
    "        \n",
    "        if smoothed_pred is None:\n",
    "            return\n",
    "        \n",
    "        # Check if prediction has been held long enough\n",
    "        if smoothed_pred == self.last_prediction:\n",
    "            hold_time = current_time - self.last_prediction_time\n",
    "            \n",
    "            if smoothed_pred == 'del' and hold_time > self.delete_hold_time:\n",
    "                self.handle_delete()\n",
    "                self.last_prediction_time = current_time  # Reset timer\n",
    "                \n",
    "            elif smoothed_pred == 'space' and hold_time > self.space_hold_time:\n",
    "                self.handle_space()\n",
    "                self.last_prediction_time = current_time  # Reset timer\n",
    "                \n",
    "            elif smoothed_pred not in ['del', 'space', 'nothing'] and hold_time > self.prediction_hold_time:\n",
    "                self.add_letter(smoothed_pred)\n",
    "                self.last_prediction_time = current_time  # Reset timer\n",
    "        else:\n",
    "            # New prediction\n",
    "            self.last_prediction = smoothed_pred\n",
    "            self.last_prediction_time = current_time\n",
    "    \n",
    "    def add_letter(self, letter):\n",
    "        \"\"\"Add letter to current word\"\"\"\n",
    "        if letter not in ['del', 'space', 'nothing']:\n",
    "            self.current_word += letter.lower()\n",
    "    \n",
    "    def handle_delete(self):\n",
    "        \"\"\"Handle delete action\"\"\"\n",
    "        if self.current_word:\n",
    "            self.current_word = self.current_word[:-1]\n",
    "        elif self.sentence:\n",
    "            # If no current word, remove last character from sentence\n",
    "            self.sentence = self.sentence[:-1]\n",
    "    \n",
    "    def handle_space(self):\n",
    "        \"\"\"Handle space action - finalize word and add to sentence\"\"\"\n",
    "        if self.current_word:\n",
    "            # Add word to history\n",
    "            self.word_history.append(self.current_word)\n",
    "            \n",
    "            # Add to sentence\n",
    "            if self.sentence:\n",
    "                self.sentence += \" \" + self.current_word\n",
    "            else:\n",
    "                self.sentence = self.current_word\n",
    "            \n",
    "            # Clear current word\n",
    "            self.current_word = \"\"\n",
    "    \n",
    "    def get_word_suggestions(self):\n",
    "        \"\"\"Get word suggestions based on current partial word\"\"\"\n",
    "        if len(self.current_word) < 2:\n",
    "            return []\n",
    "        \n",
    "        suggestions = []\n",
    "        for word in self.common_words:\n",
    "            if word.startswith(self.current_word.lower()):\n",
    "                suggestions.append(word)\n",
    "        \n",
    "        return sorted(suggestions)[:3]  # Return top 3 suggestions\n",
    "    \n",
    "    def get_status(self):\n",
    "        \"\"\"Get current status for display\"\"\"\n",
    "        return {\n",
    "            'current_word': self.current_word,\n",
    "            'sentence': self.sentence,\n",
    "            'suggestions': self.get_word_suggestions(),\n",
    "            'last_prediction': self.last_prediction,\n",
    "            'word_count': len(self.word_history)\n",
    "        }\n",
    "    \n",
    "    def clear_all(self):\n",
    "        \"\"\"Clear everything\"\"\"\n",
    "        self.current_word = \"\"\n",
    "        self.sentence = \"\"\n",
    "        self.word_history = []\n",
    "    \n",
    "    def undo_last_word(self):\n",
    "        \"\"\"Undo last word\"\"\"\n",
    "        if self.word_history:\n",
    "            removed_word = self.word_history.pop()\n",
    "            # Rebuild sentence without last word\n",
    "            self.sentence = \" \".join(self.word_history)\n",
    "    \n",
    "    def save_session(self, filename=\"asl_session.json\"):\n",
    "        \"\"\"Save current session\"\"\"\n",
    "        session_data = {\n",
    "            'sentence': self.sentence,\n",
    "            'word_history': self.word_history,\n",
    "            'timestamp': time.time()\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(session_data, f)\n",
    "    \n",
    "    def load_session(self, filename=\"asl_session.json\"):\n",
    "        \"\"\"Load previous session\"\"\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r') as f:\n",
    "                session_data = json.load(f)\n",
    "                self.sentence = session_data.get('sentence', '')\n",
    "                self.word_history = session_data.get('word_history', [])\n",
    "\n",
    "def create_resnet_model(num_classes):\n",
    "    \"\"\"Create ResNet18 model\"\"\"\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_resnet_model(model_path, num_classes=29):\n",
    "    \"\"\"Load trained ResNet model\"\"\"\n",
    "    model = create_resnet_model(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_frame(frame, image_size=224):\n",
    "    \"\"\"Preprocess frame for ResNet\"\"\"\n",
    "    # Convert BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "    \n",
    "    # Apply transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    tensor = transform(pil_image).unsqueeze(0)\n",
    "    return tensor\n",
    "\n",
    "def draw_ui(frame, spelling_engine, predicted_class, confidence, fps):\n",
    "    \"\"\"Draw enhanced UI with finger spelling information\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    status = spelling_engine.get_status()\n",
    "    \n",
    "    # Draw semi-transparent background for text\n",
    "    overlay = frame.copy()\n",
    "    \n",
    "    # Top panel for current prediction\n",
    "    cv2.rectangle(overlay, (0, 0), (w, 120), (0, 0, 0), -1)\n",
    "    \n",
    "    # Bottom panel for sentence building\n",
    "    cv2.rectangle(overlay, (0, h-200), (w, h), (0, 0, 0), -1)\n",
    "    \n",
    "    # Blend overlay\n",
    "    alpha = 0.7\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "    \n",
    "    # Current prediction with confidence\n",
    "    pred_text = f\"Sign: {predicted_class} ({confidence:.2f})\"\n",
    "    cv2.putText(frame, pred_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "    # FPS\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (w-100, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    # Current word being spelled\n",
    "    word_text = f\"Current Word: {status['current_word']}_\"\n",
    "    cv2.putText(frame, word_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "    \n",
    "    # Word suggestions\n",
    "    suggestions = status['suggestions']\n",
    "    if suggestions:\n",
    "        sugg_text = f\"Suggestions: {', '.join(suggestions)}\"\n",
    "        cv2.putText(frame, sugg_text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "    \n",
    "    # Sentence display (bottom panel)\n",
    "    sentence_y_start = h - 180\n",
    "    \n",
    "    # Title\n",
    "    cv2.putText(frame, \"Sentence:\", (10, sentence_y_start), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "    \n",
    "    # Sentence text (wrap if too long)\n",
    "    sentence = status['sentence']\n",
    "    if len(sentence) > 80:  # Wrap long sentences\n",
    "        lines = [sentence[i:i+80] for i in range(0, len(sentence), 80)]\n",
    "        for i, line in enumerate(lines[-3:]):  # Show last 3 lines\n",
    "            cv2.putText(frame, line, (10, sentence_y_start + 30 + i*25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "    else:\n",
    "        cv2.putText(frame, sentence, (10, sentence_y_start + 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "    \n",
    "    # Instructions\n",
    "    instructions = [\n",
    "        \"Hold gesture for 1.5s to add letter\",\n",
    "        \"Hold SPACE for 1s to add word\",\n",
    "        \"Hold DEL for 2s to delete\",\n",
    "        \"Keys: C-clear, U-undo, S-save, Q-quit\"\n",
    "    ]\n",
    "    \n",
    "    start_y = sentence_y_start + 80\n",
    "    for i, instruction in enumerate(instructions):\n",
    "        cv2.putText(frame, instruction, (10, start_y + i*20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 1)\n",
    "    \n",
    "    # Progress indicator for held gestures\n",
    "    if status['last_prediction'] in ['del', 'space'] or (status['last_prediction'] not in ['nothing']):\n",
    "        current_time = time.time()\n",
    "        hold_time = current_time - spelling_engine.last_prediction_time\n",
    "        \n",
    "        if status['last_prediction'] == 'del':\n",
    "            required_time = spelling_engine.delete_hold_time\n",
    "            color = (0, 0, 255)  # Red\n",
    "        elif status['last_prediction'] == 'space':\n",
    "            required_time = spelling_engine.space_hold_time\n",
    "            color = (255, 0, 0)  # Blue\n",
    "        else:\n",
    "            required_time = spelling_engine.prediction_hold_time\n",
    "            color = (0, 255, 0)  # Green\n",
    "        \n",
    "        if hold_time < required_time:\n",
    "            progress = hold_time / required_time\n",
    "            bar_width = int(200 * progress)\n",
    "            cv2.rectangle(frame, (w-220, 50), (w-220 + bar_width, 70), color, -1)\n",
    "            cv2.rectangle(frame, (w-220, 50), (w-20, 70), (255, 255, 255), 2)\n",
    "\n",
    "def run_enhanced_asl_detection():\n",
    "    \"\"\"Run enhanced ASL detection with finger spelling\"\"\"\n",
    "    # Load model\n",
    "    model_path = \"models/asl_resnet_model.pth\"\n",
    "    \n",
    "    try:\n",
    "        model = load_resnet_model(model_path)\n",
    "        print(\"Model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"Make sure the model file exists at: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize finger spelling engine\n",
    "    spelling_engine = FingerSpellingEngine()\n",
    "    \n",
    "    # Try to load previous session\n",
    "    spelling_engine.load_session()\n",
    "    \n",
    "    # Initialize camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera\")\n",
    "        return\n",
    "    \n",
    "    print(\"Enhanced ASL Detection with Finger Spelling Started!\")\n",
    "    print(\"Controls:\")\n",
    "    print(\"  Hold gestures to spell words\")\n",
    "    print(\"  C - Clear all\")\n",
    "    print(\"  U - Undo last word\")\n",
    "    print(\"  S - Save session\")\n",
    "    print(\"  Q - Quit\")\n",
    "    \n",
    "    # FPS calculation\n",
    "    fps_counter = 0\n",
    "    fps_start_time = time.time()\n",
    "    current_fps = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame\")\n",
    "            break\n",
    "        \n",
    "        # Flip frame horizontally for mirror effect\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Calculate FPS\n",
    "        fps_counter += 1\n",
    "        if fps_counter % 30 == 0:  # Update FPS every 30 frames\n",
    "            current_fps = 30 / (time.time() - fps_start_time)\n",
    "            fps_start_time = time.time()\n",
    "        \n",
    "        # Create ROI for hand detection\n",
    "        h, w = frame.shape[:2]\n",
    "        roi_size = 300\n",
    "        x1 = (w - roi_size) // 2\n",
    "        y1 = (h - roi_size) // 2 - 50  # Move ROI up a bit\n",
    "        x2 = x1 + roi_size\n",
    "        y2 = y1 + roi_size\n",
    "        \n",
    "        # Extract ROI\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        # Preprocess and predict\n",
    "        try:\n",
    "            input_tensor = preprocess_frame(roi)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                confidence, predicted = torch.max(probabilities, 1)\n",
    "                \n",
    "                predicted_class = ASL_CLASSES[predicted.item()]\n",
    "                confidence_score = confidence.item()\n",
    "            \n",
    "            # Process prediction with spelling engine\n",
    "            spelling_engine.process_prediction(predicted_class, confidence_score)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            predicted_class = \"error\"\n",
    "            confidence_score = 0\n",
    "        \n",
    "        # Draw ROI rectangle\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw enhanced UI\n",
    "        draw_ui(frame, spelling_engine, predicted_class, confidence_score, current_fps)\n",
    "        \n",
    "        cv2.imshow('Enhanced ASL Detection - Finger Spelling', frame)\n",
    "        \n",
    "        # Handle keyboard input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            spelling_engine.clear_all()\n",
    "            print(\"Cleared all text\")\n",
    "        elif key == ord('u'):\n",
    "            spelling_engine.undo_last_word()\n",
    "            print(\"Undid last word\")\n",
    "        elif key == ord('s'):\n",
    "            spelling_engine.save_session()\n",
    "            print(\"Session saved\")\n",
    "        elif key == ord('l'):\n",
    "            spelling_engine.load_session()\n",
    "            print(\"Session loaded\")\n",
    "    \n",
    "    # Save session before quitting\n",
    "    spelling_engine.save_session()\n",
    "    print(f\"Final sentence: {spelling_engine.sentence}\")\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_enhanced_asl_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ca006d8-6116-4e5f-a9b5-254959d7f74a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: models/asl_resnet_model.pth\n",
      "Started. Controls: Q Quit | C Clear | U Undo | S Save | L Load | G Enter GT | A Toggle TTS | V Toggle STT | E Export Accuracy\n",
      "Final sentence: wbcciiiiiiii\n",
      "Accuracy: 0.00% (0/0)\n"
     ]
    }
   ],
   "source": [
    "# enhanced_asl_detection.py\n",
    "# Requirements:\n",
    "#   pip install torch torchvision opencv-python Pillow pyttsx3 SpeechRecognition\n",
    "#   (optional) pip install pyaudio   -> required for live microphone STT\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import threading\n",
    "from collections import deque, Counter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Try optional imports\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torchvision import transforms, models\n",
    "except Exception as e:\n",
    "    torch = None\n",
    "    print(\"Warning: torch not available. Model inference will fail. Install torch to enable prediction.\")\n",
    "\n",
    "try:\n",
    "    import speech_recognition as sr\n",
    "except Exception:\n",
    "    sr = None\n",
    "\n",
    "try:\n",
    "    import pyttsx3\n",
    "except Exception:\n",
    "    pyttsx3 = None\n",
    "\n",
    "# ASL classes (29)\n",
    "ASL_CLASSES = ['A','B','C','D','E','F','G','H','I','J',\n",
    "               'K','L','M','N','O','P','Q','R','S','T',\n",
    "               'U','V','W','X','Y','Z','del','nothing','space']\n",
    "\n",
    "# ---------------------------\n",
    "# Accuracy tracker\n",
    "# ---------------------------\n",
    "class AccuracyTracker:\n",
    "    def __init__(self):\n",
    "        self.predictions = []  # list of (timestamp, predicted, confidence)\n",
    "        self.ground_truths = []  # list of (timestamp, ground_truth)\n",
    "    \n",
    "    def log_prediction(self, predicted, confidence):\n",
    "        self.predictions.append({\n",
    "            'time': time.time(),\n",
    "            'predicted': predicted,\n",
    "            'confidence': float(confidence)\n",
    "        })\n",
    "    \n",
    "    def add_ground_truth(self, gt):\n",
    "        # link ground truth to last prediction time (best-effort)\n",
    "        self.ground_truths.append({\n",
    "            'time': time.time(),\n",
    "            'ground_truth': gt\n",
    "        })\n",
    "    \n",
    "    def compute_accuracy(self):\n",
    "        # Pair ground truths to closest prior prediction (naive)\n",
    "        if not self.ground_truths or not self.predictions:\n",
    "            return 0.0, 0, 0\n",
    "        correct = 0\n",
    "        matched = 0\n",
    "        for gt in self.ground_truths:\n",
    "            # find last prediction before gt.time\n",
    "            preds_before = [p for p in self.predictions if p['time'] <= gt['time']]\n",
    "            if not preds_before:\n",
    "                continue\n",
    "            last_pred = preds_before[-1]\n",
    "            matched += 1\n",
    "            if last_pred['predicted'].lower() == gt['ground_truth'].lower():\n",
    "                correct += 1\n",
    "        acc = (correct / matched) if matched else 0.0\n",
    "        return acc, correct, matched\n",
    "\n",
    "    def export(self, fname=\"accuracy_log.json\"):\n",
    "        data = {\n",
    "            'predictions': self.predictions,\n",
    "            'ground_truths': self.ground_truths,\n",
    "            'computed_accuracy': self.compute_accuracy()\n",
    "        }\n",
    "        with open(fname, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "# ---------------------------\n",
    "# FingerSpellingEngine (cleaned)\n",
    "# ---------------------------\n",
    "class FingerSpellingEngine:\n",
    "    def __init__(self, auto_speak=False):\n",
    "        self.current_word = \"\"\n",
    "        self.sentence = \"\"\n",
    "        self.word_history = []\n",
    "        self.last_prediction = \"\"\n",
    "        self.last_prediction_time = 0.0\n",
    "        self.prediction_hold_time = 1.5  # seconds\n",
    "        self.delete_hold_time = 2.0\n",
    "        self.space_hold_time = 1.0\n",
    "\n",
    "        # smoothing\n",
    "        self.prediction_buffer = deque(maxlen=10)\n",
    "        self.confidence_threshold = 0.75\n",
    "\n",
    "        # common words for suggestions\n",
    "        self.common_words = self.load_common_words()\n",
    "\n",
    "        # Audio\n",
    "        self.auto_speak = auto_speak\n",
    "        self.tts_engine = None\n",
    "        if pyttsx3 is not None:\n",
    "            try:\n",
    "                self.tts_engine = pyttsx3.init()\n",
    "            except Exception as e:\n",
    "                self.tts_engine = None\n",
    "        # Accuracy tracker\n",
    "        self.accuracy_tracker = AccuracyTracker()\n",
    "\n",
    "    def load_common_words(self):\n",
    "        basic = [\n",
    "            'hello','world','how','are','you','what','when','where','why','who',\n",
    "            'good','bad','yes','no','please','thank','sorry','help','love','like',\n",
    "            'want','need','time','day','night','morning','afternoon','evening',\n",
    "            'food','water','home','work','school','friend','family','happy','sad',\n",
    "            'the','and','for','with','this','that','have','will','can','could'\n",
    "        ]\n",
    "        return set(basic)\n",
    "\n",
    "    def smooth_prediction(self, predicted_class, confidence):\n",
    "        self.prediction_buffer.append((predicted_class, confidence))\n",
    "        high_conf = [p for p,c in self.prediction_buffer if c > self.confidence_threshold]\n",
    "        if len(high_conf) < 3:\n",
    "            return None, 0.0\n",
    "        counter = Counter(high_conf)\n",
    "        pred, _ = counter.most_common(1)[0]\n",
    "        avg_conf = np.mean([c for p,c in self.prediction_buffer if p == pred])\n",
    "        return pred, float(avg_conf)\n",
    "\n",
    "    def process_prediction(self, predicted_class, confidence):\n",
    "        now = time.time()\n",
    "        # log every raw prediction for accuracy analysis\n",
    "        self.accuracy_tracker.log_prediction(predicted_class, confidence)\n",
    "\n",
    "        smoothed, sm_conf = self.smooth_prediction(predicted_class, confidence)\n",
    "        if smoothed is None:\n",
    "            return\n",
    "\n",
    "        if smoothed == self.last_prediction:\n",
    "            hold_time = now - self.last_prediction_time\n",
    "            if smoothed == 'del' and hold_time > self.delete_hold_time:\n",
    "                self.handle_delete()\n",
    "                self.last_prediction_time = now\n",
    "            elif smoothed == 'space' and hold_time > self.space_hold_time:\n",
    "                self.handle_space()\n",
    "                self.last_prediction_time = now\n",
    "            elif smoothed not in ['del','space','nothing'] and hold_time > self.prediction_hold_time:\n",
    "                self.add_letter(smoothed)\n",
    "                self.last_prediction_time = now\n",
    "        else:\n",
    "            self.last_prediction = smoothed\n",
    "            self.last_prediction_time = now\n",
    "\n",
    "    def add_letter(self, letter):\n",
    "        if letter not in ['del','space','nothing']:\n",
    "            self.current_word += letter.lower()\n",
    "            if self.auto_speak and self.tts_engine:\n",
    "                # speak the letter\n",
    "                try:\n",
    "                    self.tts_engine.say(letter)\n",
    "                    self.tts_engine.runAndWait()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    def handle_delete(self):\n",
    "        if self.current_word:\n",
    "            self.current_word = self.current_word[:-1]\n",
    "        elif self.sentence:\n",
    "            self.sentence = self.sentence[:-1]\n",
    "\n",
    "    def handle_space(self):\n",
    "        if self.current_word:\n",
    "            self.word_history.append(self.current_word)\n",
    "            if self.sentence:\n",
    "                self.sentence += \" \" + self.current_word\n",
    "            else:\n",
    "                self.sentence = self.current_word\n",
    "            # Optionally speak word\n",
    "            if self.auto_speak and self.tts_engine:\n",
    "                try:\n",
    "                    self.tts_engine.say(self.current_word)\n",
    "                    self.tts_engine.runAndWait()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            self.current_word = \"\"\n",
    "\n",
    "    def get_word_suggestions(self):\n",
    "        if len(self.current_word) < 2:\n",
    "            return []\n",
    "        s = self.current_word.lower()\n",
    "        suggestions = [w for w in self.common_words if w.startswith(s)]\n",
    "        return sorted(suggestions)[:3]\n",
    "\n",
    "    def get_status(self):\n",
    "        acc, correct, matched = self.accuracy_tracker.compute_accuracy()\n",
    "        return {\n",
    "            'current_word': self.current_word,\n",
    "            'sentence': self.sentence,\n",
    "            'suggestions': self.get_word_suggestions(),\n",
    "            'last_prediction': self.last_prediction,\n",
    "            'word_count': len(self.word_history),\n",
    "            'accuracy': acc,\n",
    "            'accuracy_details': (correct, matched)\n",
    "        }\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.current_word = \"\"\n",
    "        self.sentence = \"\"\n",
    "        self.word_history = []\n",
    "\n",
    "    def undo_last_word(self):\n",
    "        if self.word_history:\n",
    "            removed = self.word_history.pop()\n",
    "            self.sentence = \" \".join(self.word_history)\n",
    "\n",
    "    def save_session(self, filename=\"asl_session.json\"):\n",
    "        data = {\n",
    "            'sentence': self.sentence,\n",
    "            'word_history': self.word_history,\n",
    "            'timestamp': time.time()\n",
    "        }\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "    def load_session(self, filename=\"asl_session.json\"):\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                self.sentence = data.get('sentence','')\n",
    "                self.word_history = data.get('word_history',[])\n",
    "\n",
    "# ---------------------------\n",
    "# Model utilities\n",
    "# ---------------------------\n",
    "def create_resnet_model(num_classes):\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_resnet_model(model_path, num_classes=29):\n",
    "    if torch is None:\n",
    "        raise RuntimeError(\"torch not available\")\n",
    "    model = create_resnet_model(num_classes)\n",
    "    state = torch.load(model_path, map_location='cpu')\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_frame(frame, image_size=224):\n",
    "    # roi -> RGB PIL -> tensor\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil = Image.fromarray(rgb)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "    return transform(pil).unsqueeze(0)\n",
    "\n",
    "# ---------------------------\n",
    "# UI drawing\n",
    "# ---------------------------\n",
    "def draw_ui(frame, spelling_engine, predicted_class, confidence, fps):\n",
    "    h, w = frame.shape[:2]\n",
    "    status = spelling_engine.get_status()\n",
    "\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (0,0),(w,120), (0,0,0), -1)\n",
    "    cv2.rectangle(overlay, (0,h-200),(w,h), (0,0,0), -1)\n",
    "    alpha = 0.6\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1-alpha, 0, frame)\n",
    "\n",
    "    pred_text = f\"Sign: {predicted_class} ({confidence:.2f})\"\n",
    "    cv2.putText(frame, pred_text, (10, 26), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (w-140, 26), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)\n",
    "    acc_text = f\"Accuracy: {status['accuracy']:.1%} ({status['accuracy_details'][0]}/{status['accuracy_details'][1]})\"\n",
    "    cv2.putText(frame, acc_text, (w-400, 52), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)\n",
    "\n",
    "    word_text = f\"Current Word: {status['current_word']}_\"\n",
    "    cv2.putText(frame, word_text, (10, 56), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "\n",
    "    suggestions = status['suggestions']\n",
    "    if suggestions:\n",
    "        cv2.putText(frame, \"Suggestions: \" + \", \".join(suggestions), (10, 86), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "\n",
    "    sentence_y = h - 170\n",
    "    cv2.putText(frame, \"Sentence:\", (10, sentence_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)\n",
    "    sentence = status['sentence']\n",
    "    if len(sentence) > 80:\n",
    "        lines = [sentence[i:i+80] for i in range(0, len(sentence), 80)]\n",
    "        for i, line in enumerate(lines[-3:]):\n",
    "            cv2.putText(frame, line, (10, sentence_y + 25 + i*22), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1)\n",
    "    else:\n",
    "        cv2.putText(frame, sentence, (10, sentence_y + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)\n",
    "\n",
    "    instructions = [\"Hold gesture to add letter\", \"Hold SPACE to add word\", \"Hold DEL to delete\",\n",
    "                    \"Keys: C-clear U-undo S-save G-enter-gt Q-quit A-toggle-tts V-toggle-stt E-export-accuracy\"]\n",
    "    for i, inst in enumerate(instructions):\n",
    "        cv2.putText(frame, inst, (10, h-40 + i*0), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (180,180,180), 1)\n",
    "\n",
    "# ---------------------------\n",
    "# Optional STT thread\n",
    "# ---------------------------\n",
    "class SpeechListener(threading.Thread):\n",
    "    def __init__(self, spelling_engine):\n",
    "        super().__init__(daemon=True)\n",
    "        self.engine = spelling_engine\n",
    "        self.running = True\n",
    "        self.recognizer = None\n",
    "        self.microphone = None\n",
    "        if sr is not None:\n",
    "            try:\n",
    "                self.recognizer = sr.Recognizer()\n",
    "                self.microphone = sr.Microphone()\n",
    "            except Exception as e:\n",
    "                self.recognizer = None\n",
    "                self.microphone = None\n",
    "                print(\"SpeechRecognition or microphone not available. STT disabled.\")\n",
    "        else:\n",
    "            print(\"SpeechRecognition not installed. STT disabled.\")\n",
    "\n",
    "    def run(self):\n",
    "        if not self.recognizer or not self.microphone:\n",
    "            return\n",
    "        with self.microphone as source:\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "        while self.running:\n",
    "            try:\n",
    "                with self.microphone as source:\n",
    "                    audio = self.recognizer.listen(source, phrase_time_limit=4)\n",
    "                text = self.recognizer.recognize_google(audio)  # online; change if offline engine used\n",
    "                # append recognized text\n",
    "                if text:\n",
    "                    if self.engine.sentence:\n",
    "                        self.engine.sentence += \" \" + text\n",
    "                    else:\n",
    "                        self.engine.sentence = text\n",
    "                    # optionally TTS\n",
    "                    if self.engine.auto_speak and self.engine.tts_engine:\n",
    "                        try:\n",
    "                            self.engine.tts_engine.say(text)\n",
    "                            self.engine.tts_engine.runAndWait()\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    print(\"[STT] Recognized:\", text)\n",
    "            except Exception as e:\n",
    "                # avoid spamming errors\n",
    "                time.sleep(0.5)\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "\n",
    "# ---------------------------\n",
    "# Main run loop\n",
    "# ---------------------------\n",
    "def run_enhanced_asl_detection(model_path=\"models/asl_resnet_model.pth\", use_stt=False):\n",
    "    # Model load\n",
    "    model = None\n",
    "    try:\n",
    "        model = load_resnet_model(model_path)\n",
    "        print(\"Model loaded:\", model_path)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: could not load model:\", e)\n",
    "        print(\"Make sure model exists and torch is installed. Continuing in demo mode (no predictions).\")\n",
    "\n",
    "    # spelling engine\n",
    "    spelling_engine = FingerSpellingEngine(auto_speak=False)\n",
    "    spelling_engine.load_session()\n",
    "\n",
    "    # STT thread\n",
    "    stt_thread = None\n",
    "    stt_on = False\n",
    "    if use_stt:\n",
    "        stt_thread = SpeechListener(spelling_engine)\n",
    "        stt_thread.start()\n",
    "        stt_on = True\n",
    "\n",
    "    # video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera\")\n",
    "        return\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    fps_count = 0\n",
    "    fps_time = time.time()\n",
    "    current_fps = 0.0\n",
    "\n",
    "    predicted_class = \"none\"\n",
    "    confidence_score = 0.0\n",
    "\n",
    "    print(\"Started. Controls: Q Quit | C Clear | U Undo | S Save | L Load | G Enter GT | A Toggle TTS | V Toggle STT | E Export Accuracy\")\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            fps_count += 1\n",
    "            if fps_count % 30 == 0:\n",
    "                now = time.time()\n",
    "                current_fps = 30.0 / (now - fps_time) if (now - fps_time) > 0 else 0.0\n",
    "                fps_time = now\n",
    "\n",
    "            h, w = frame.shape[:2]\n",
    "            roi_size = 300\n",
    "            x1 = (w - roi_size) // 2\n",
    "            y1 = (h - roi_size) // 2 - 50\n",
    "            x2, y2 = x1 + roi_size, y1 + roi_size\n",
    "            roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Inference if model available\n",
    "            if model is not None and torch is not None:\n",
    "                try:\n",
    "                    input_tensor = preprocess_frame(roi)\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(input_tensor)\n",
    "                        probs = torch.softmax(outputs, dim=1)\n",
    "                        conf, idx = torch.max(probs, 1)\n",
    "                        predicted_class = ASL_CLASSES[int(idx.item())]\n",
    "                        confidence_score = float(conf.item())\n",
    "                except Exception as e:\n",
    "                    predicted_class = \"error\"\n",
    "                    confidence_score = 0.0\n",
    "            else:\n",
    "                # demo: show nothing\n",
    "                predicted_class = \"nothing\"\n",
    "                confidence_score = 0.0\n",
    "\n",
    "            # process prediction\n",
    "            spelling_engine.process_prediction(predicted_class, confidence_score)\n",
    "\n",
    "            # draw\n",
    "            cv2.rectangle(frame, (x1,y1),(x2,y2),(0,255,0),2)\n",
    "            draw_ui(frame, spelling_engine, predicted_class, confidence_score, current_fps)\n",
    "            cv2.imshow(\"Enhanced ASL Detection - Finger Spelling\", frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('c'):\n",
    "                spelling_engine.clear_all()\n",
    "                print(\"Cleared all\")\n",
    "            elif key == ord('u'):\n",
    "                spelling_engine.undo_last_word()\n",
    "                print(\"Undid last word\")\n",
    "            elif key == ord('s'):\n",
    "                spelling_engine.save_session()\n",
    "                print(\"Session saved\")\n",
    "            elif key == ord('l'):\n",
    "                spelling_engine.load_session()\n",
    "                print(\"Session loaded\")\n",
    "            elif key == ord('g'):\n",
    "                # enter ground truth for last prediction\n",
    "                gt = input(\"Enter ground-truth letter/word for last prediction: \").strip()\n",
    "                if gt:\n",
    "                    spelling_engine.accuracy_tracker.add_ground_truth(gt)\n",
    "                    print(\"Ground truth saved.\")\n",
    "            elif key == ord('a'):\n",
    "                # toggle auto-speak\n",
    "                spelling_engine.auto_speak = not spelling_engine.auto_speak\n",
    "                print(\"Auto-speak:\", spelling_engine.auto_speak)\n",
    "            elif key == ord('v'):\n",
    "                # toggle STT\n",
    "                if stt_on:\n",
    "                    if stt_thread:\n",
    "                        stt_thread.stop()\n",
    "                    stt_on = False\n",
    "                    print(\"STT stopped\")\n",
    "                else:\n",
    "                    if sr is None:\n",
    "                        print(\"SpeechRecognition not available, cannot start STT.\")\n",
    "                    else:\n",
    "                        stt_thread = SpeechListener(spelling_engine)\n",
    "                        stt_thread.start()\n",
    "                        stt_on = True\n",
    "                        print(\"STT started\")\n",
    "            elif key == ord('e'):\n",
    "                # export accuracy\n",
    "                spelling_engine.accuracy_tracker.export()\n",
    "                print(\"Exported accuracy_log.json\")\n",
    "\n",
    "    finally:\n",
    "        if stt_thread:\n",
    "            stt_thread.stop()\n",
    "        spelling_engine.save_session()\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Final sentence:\", spelling_engine.sentence)\n",
    "        acc, c, m = spelling_engine.accuracy_tracker.compute_accuracy()\n",
    "        print(f\"Accuracy: {acc:.2%} ({c}/{m})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # change model path if needed\n",
    "    run_enhanced_asl_detection(model_path=\"models/asl_resnet_model.pth\", use_stt=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd95cd6b-f217-43ae-974a-4d4d3ffaee29",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2082685946.py, line 714)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 714\u001b[1;36m\u001b[0m\n\u001b[1;33m    confidence, stability, current_fps, han\u001b[0m\n\u001b[1;37m                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
